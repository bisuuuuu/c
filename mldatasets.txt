ml datasets qs

Sepal length(cm),Sepal width(cm),Petal length(cm),Petal width(cm),Class
5.1,3.5,1.4,0.2,setosa
4.9,3.0,1.4,0.2,setosa
4.6,3.1,1.5,0.2,setosa
4.7,3.2,1.3,0.2,setosa
7.0,3.2,1.5,1.5,versicolor
6.4,3.2,4.5,1.5,versicolor
6.9,3.1,4.9,1.5,versicolor
6.3,3.3,6.0,2.5,virginica
7.1,3.0,5.9,2.1,virginica
6.3,2.9,5.6,1.8,virginica
Save this file as iris_subset.csv.


 Read and Display CSV
import pandas as pd

# Read the CSV file
df = pd.read_csv('iris_subset.csv')

# Display the dataset
print("Iris Subset Dataset:")
print(df)



Statistical Analysis & Visualization
(a) Standard Deviation & Scatter Plot
import numpy as np
import matplotlib.pyplot as plt

# Calculate standard deviation of each numerical feature
std_dev = df.describe().loc['std']
print("\nStandard Deviations:")
print(std_dev[['Sepal length(cm)', 'Sepal width(cm)', 'Petal length(cm)', 'Petal width(cm)']])

# Scatter plot: Sepal Length vs Sepal Width
plt.figure(figsize=(8,5))
plt.scatter(df['Sepal length(cm)'], df['Sepal width(cm)'], c='blue', marker='o')
plt.title('Scatter Plot: Sepal Length vs Sepal Width')
plt.xlabel('Sepal Length (cm)')
plt.ylabel('Sepal Width (cm)')
plt.grid(True)
plt.show()




 Step 3: KNN Classification (k=3)
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import KNeighborsClassifier

# Encode the class labels
le = LabelEncoder()
df['Class_encoded'] = le.fit_transform(df['Class'])

# Features and labels
X = df[['Sepal length(cm)', 'Sepal width(cm)', 'Petal length(cm)', 'Petal width(cm)']]
y = df['Class_encoded']

# Create and train KNN model
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X, y)

# New data for prediction
new_instance = [[6.3, 2.8, 5.1, 1.5]]
pred = knn.predict(new_instance)

# Decode the predicted label
predicted_class = le.inverse_transform(pred)

print(f"\nPredicted class for {new_instance} is: {predicted_class[0]}")
